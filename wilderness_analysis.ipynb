{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilderness World Heritage analysis for the marine environment (no Antarctica)\n",
    "---\n",
    "Based on the discussion with Bastian and various people.\n",
    "\n",
    "The spatial analysis was done outside of this notebook. In a nutshell, the spatial component dealt with the question of how much of [cumulative marine pressure](http://www.nature.com/ncomms/2015/150714/ncomms8615/full/ncomms8615.html) there is in each unit (see below for such a hypothetical biogeographic classification). The analysis was carried out in such a way that the aggregation happens in the later stage and if thresholds are to be changed (very likely due to the explorative nature of such exercise), it requires minimum efforts without having to re-run any spatial analysis, which are time-consuming and prone to error.\n",
    "\n",
    "Nodata in the result (when converting rasters to numpy) is also removed thus saving the efforts of having to manually remove them here.\n",
    "\n",
    "[**concise methodology here**](./WH marine wilderness methodology.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load default libraries\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# make sure gdal is correctly installed\n",
    "from osgeo import gdal\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get quantiles from the input raster data (global threshold from raw data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to load the original raster in order to calculateits quantiles. They are used to define thresholds to explore the extent of marine wilderness areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raster2array(rasterfn):\n",
    "    raster = gdal.Open(rasterfn)\n",
    "    band = raster.GetRasterBand(1)\n",
    "    return band.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_array = raster2array('global_cumul_impact_2013_all_layers.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_array_f = g_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330730483"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(g_array_f == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of non-zero values in the raw raster dataset: 414635567\n"
     ]
    }
   ],
   "source": [
    "print('The total number of non-zero values in the raw raster dataset:', g_array_f.size - (g_array_f==0).sum())\n",
    "\n",
    "## in fact the following should be used for testing equality of float dtypes. Because the result remains\\\n",
    "## the same thus the simpler option is used.\n",
    "\n",
    "## (np.isclose(g_array_f, 0.0)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of non-zero values is notably different from esri's calculation, which stands at 414,347,791, less than what's calculated here and is 300,000 fewer zeros. This suggests esri may be using a bigger tolerence value, i.e. what is considered small enough to be regarded as zero .\n",
    "\n",
    "Now, get the quantiles... this threshold is subject to change. For the time being, arbitary values of 1%, 3%, 5% and 10% are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## the percentile function applied to the sliced array, i.e., those with values greater than 0\n",
    "quantiles = [np.percentile(g_array_f[~(g_array_f == 0)], quantile) for quantile in [1,3,5,10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.67987793684005737,\n",
       " 1.2613298869132996,\n",
       " 1.5064566135406494,\n",
       " 1.8049463033676147]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold cut-off value: 0.67987793684\n",
      "Threshold cut-off value: 1.26132988691\n",
      "Threshold cut-off value: 1.50645661354\n",
      "Threshold cut-off value: 1.80494630337\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(['Threshold cut-off value: '+ str(threshold) for threshold in quantiles]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a href='#data'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap between biogeography and marine pressure (global threshold) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothetical biogeographical classification of the marine environmental within EEZ is described as a combination of MEOW (Marine Ecoregional of the World), its visual representation (called hereafter MEOW visual) up to 200 nautical miles and the World's pelagic provinces. The spatial data was prepared in a way such that from the coastline outwards disjoint polygons represents: MEOW (up to 200 meter depth, inner/red), MEOW visual overlaps with pelagic provinces (middle/green), pelagic provinces that do not overlap with MEOW visual (outer/blue). This is purely a spatial aggregation based on the above data and the World Vector Shoreline EEZ. See below for example.\n",
    "\n",
    "![title](classification.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `input_data` table, which describes the intersection between the marine pressure layer and the marine ecoregion/pelagic provinces classification. The `input_attr` table contains information on the relationship between `OBJECTID` and each raster pixel value.\n",
    "- `OBJECTID` (one) - pixel value (many)\n",
    "- `OBJECTID` (many) - attr: Province, Ecoregion, and Realm, categories (one)\n",
    "Each pixel is of height and width: 934.478 meter, making each pixel in area 0.873 $km^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732491324839999\n"
     ]
    }
   ],
   "source": [
    "# calculate cell-size in sqkm2\n",
    "cell_size = 934.478*934.478/1000000\n",
    "print(cell_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'ras_val'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the OBJECTID - ras_val table. This is a very big table and will take a long time.\n",
    "input_data = pd.read_csv('result.csv')\n",
    "# print fields\n",
    "input_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9654e-06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.ras_val.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'PROVINCE_P', 'BIOME_P', 'REALM_P', 'ECO_CODE', 'ECOREGION',\n",
       "       'PROV_CODE', 'PROVINCE', 'RLM_CODE', 'REALM', 'ALT_CODE', 'ECO_CODE_X',\n",
       "       'category', 'Shape_Length', 'Shape_Area'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the attribute table containing information about province etcb\n",
    "input_attr = pd.read_csv('attr.csv')\n",
    "# print fileds\n",
    "input_attr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total count of pixels per OBJECTID, i.e. base\n",
    "result_count = input_data.groupby('OBJECTID').count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I created four result tables containing only pixels that meet the criteria as specified by different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter result only in the top 1, 3, 5, 10 percentile (of least impacted marine areas)\n",
    "result_1, result_3, result_5, result_10 = \\\n",
    "[input_data[input_data.ras_val <= threshold].groupby('OBJECTID').count().reset_index() for threshold in quantiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to join the `input_attr` table with filtered pixel values. Replace `result10` result table if other threshold is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join base to the attribute\n",
    "attr_merge = pd.merge(input_attr, result_count, on = 'OBJECTID')\n",
    "\n",
    "# join result to the above table\n",
    "attr_merge_10 = pd.merge(attr_merge, result_10, how = 'left', on ='OBJECTID', suffixes = ('_base', '_result'))\n",
    "\n",
    "# fill ras_val_result's NaN with 0, province and realms with None. This should happen earlier\n",
    "attr_merge_10['ras_val_result'].fillna(0, inplace=True)\n",
    "attr_merge_10['PROVINCE'].fillna('None', inplace=True)\n",
    "attr_merge_10['PROVINCE_P'].fillna('None', inplace=True)\n",
    "\n",
    "# apply an aggregate function to each sub dataframe, as a result of grouping\n",
    "def apply_func(group):\n",
    "    overlap = group['ras_val_result'].sum()*cell_size # in sqkm\n",
    "    base = group['ras_val_base'].sum()*cell_size\n",
    "    per = overlap/base\n",
    "    # can have multiple columns as a result, if returened as pd.series\n",
    "    return pd.Series([overlap, per, base], index=['less_than_threshold', 'per_ltt', 'base'])\n",
    "\n",
    "# code reuse: threshold\n",
    "def calculate_wilderness_marine(threshold, groups):\n",
    "    \"\"\"<threshold to consider wilderness value>, <a python list such as ['PROVINCE', 'PROVINCE_P', attr fields]>\"\"\"\n",
    "    # filtered input data according to threshold merge\n",
    "    input_data_filtered = input_data[input_data.ras_val <= threshold].groupby('OBJECTID').count().reset_index()\n",
    "    \n",
    "    # base merge\n",
    "    base_merge = pd.merge(input_attr, result_count, on = 'OBJECTID')\n",
    "    \n",
    "    # merge the two above\n",
    "    result = pd.merge(base_merge, input_data_filtered, how='left', on='OBJECTID', suffixes=('_base', '_result'))\n",
    "        # solve no data issue\n",
    "    result['ras_val_result'].fillna(0, inplace=True)\n",
    "    result['PROVINCE'].fillna('None', inplace=True)\n",
    "    result['PROVINCE_P'].fillna('None', inplace=True)\n",
    "    \n",
    "    return result.groupby(groups).apply(apply_func).reset_index()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One all tables are joined - full attributes with pixel values, attributes can be used to specify groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCE</th>\n",
       "      <th>PROVINCE_P</th>\n",
       "      <th>category</th>\n",
       "      <th>less_than_threshold</th>\n",
       "      <th>per_ltt</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agulhas</td>\n",
       "      <td>Agulhas Current</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>4.366246e+00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5.390357e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agulhas</td>\n",
       "      <td>Benguela Current</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.824088e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agulhas</td>\n",
       "      <td>None</td>\n",
       "      <td>meow200m</td>\n",
       "      <td>1.244380e+03</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>1.224828e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agulhas</td>\n",
       "      <td>South Central Atlantic</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.505706e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amsterdam-St Paul</td>\n",
       "      <td>None</td>\n",
       "      <td>meow200m</td>\n",
       "      <td>3.999481e+02</td>\n",
       "      <td>0.442512</td>\n",
       "      <td>9.038129e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amsterdam-St Paul</td>\n",
       "      <td>Southern Indian Ocean</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>6.390088e+04</td>\n",
       "      <td>0.167804</td>\n",
       "      <td>3.808065e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amsterdam-St Paul</td>\n",
       "      <td>Southern Subtropical Front</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>4.591544e+03</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>1.398334e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Andaman</td>\n",
       "      <td>None</td>\n",
       "      <td>meow200m</td>\n",
       "      <td>2.069600e+03</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>3.084360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andaman</td>\n",
       "      <td>Northern Indian Ocean</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>6.841034e+03</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>1.452095e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arctic</td>\n",
       "      <td>Arctic</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>1.989649e+06</td>\n",
       "      <td>0.573653</td>\n",
       "      <td>3.468383e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Arctic</td>\n",
       "      <td>None</td>\n",
       "      <td>meow200m</td>\n",
       "      <td>3.042846e+06</td>\n",
       "      <td>0.437750</td>\n",
       "      <td>6.951104e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Arctic</td>\n",
       "      <td>Subarctic Atlantic</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>2.476709e+04</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>1.059351e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Arctic</td>\n",
       "      <td>Subarctic Pacific</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>1.109026e+03</td>\n",
       "      <td>0.013927</td>\n",
       "      <td>7.963072e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bay of Bengal</td>\n",
       "      <td>None</td>\n",
       "      <td>meow200m</td>\n",
       "      <td>1.846922e+03</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>2.835335e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bay of Bengal</td>\n",
       "      <td>Northern Indian Ocean</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.244395e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Benguela</td>\n",
       "      <td>Benguela Current</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>1.630356e+03</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>6.583294e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Benguela</td>\n",
       "      <td>Equatorial Atlantic</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.454134e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Benguela</td>\n",
       "      <td>None</td>\n",
       "      <td>meow200m</td>\n",
       "      <td>4.329569e+03</td>\n",
       "      <td>0.026932</td>\n",
       "      <td>1.607599e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Benguela</td>\n",
       "      <td>South Central Atlantic</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.828549e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Black Sea</td>\n",
       "      <td>Black Sea</td>\n",
       "      <td>pelagic_meow_v</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.921892e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PROVINCE                  PROVINCE_P        category  \\\n",
       "0             Agulhas             Agulhas Current  pelagic_meow_v   \n",
       "1             Agulhas            Benguela Current  pelagic_meow_v   \n",
       "2             Agulhas                        None        meow200m   \n",
       "3             Agulhas      South Central Atlantic  pelagic_meow_v   \n",
       "4   Amsterdam-St Paul                        None        meow200m   \n",
       "5   Amsterdam-St Paul       Southern Indian Ocean  pelagic_meow_v   \n",
       "6   Amsterdam-St Paul  Southern Subtropical Front  pelagic_meow_v   \n",
       "7             Andaman                        None        meow200m   \n",
       "8             Andaman       Northern Indian Ocean  pelagic_meow_v   \n",
       "9              Arctic                      Arctic  pelagic_meow_v   \n",
       "10             Arctic                        None        meow200m   \n",
       "11             Arctic          Subarctic Atlantic  pelagic_meow_v   \n",
       "12             Arctic           Subarctic Pacific  pelagic_meow_v   \n",
       "13      Bay of Bengal                        None        meow200m   \n",
       "14      Bay of Bengal       Northern Indian Ocean  pelagic_meow_v   \n",
       "15           Benguela            Benguela Current  pelagic_meow_v   \n",
       "16           Benguela         Equatorial Atlantic  pelagic_meow_v   \n",
       "17           Benguela                        None        meow200m   \n",
       "18           Benguela      South Central Atlantic  pelagic_meow_v   \n",
       "19          Black Sea                   Black Sea  pelagic_meow_v   \n",
       "\n",
       "    less_than_threshold   per_ltt          base  \n",
       "0          4.366246e+00  0.000008  5.390357e+05  \n",
       "1          0.000000e+00  0.000000  2.824088e+04  \n",
       "2          1.244380e+03  0.010160  1.224828e+05  \n",
       "3          0.000000e+00  0.000000  6.505706e+02  \n",
       "4          3.999481e+02  0.442512  9.038129e+02  \n",
       "5          6.390088e+04  0.167804  3.808065e+05  \n",
       "6          4.591544e+03  0.328358  1.398334e+04  \n",
       "7          2.069600e+03  0.006710  3.084360e+05  \n",
       "8          6.841034e+03  0.004711  1.452095e+06  \n",
       "9          1.989649e+06  0.573653  3.468383e+06  \n",
       "10         3.042846e+06  0.437750  6.951104e+06  \n",
       "11         2.476709e+04  0.023380  1.059351e+06  \n",
       "12         1.109026e+03  0.013927  7.963072e+04  \n",
       "13         1.846922e+03  0.006514  2.835335e+05  \n",
       "14         0.000000e+00  0.000000  6.244395e+05  \n",
       "15         1.630356e+03  0.002477  6.583294e+05  \n",
       "16         0.000000e+00  0.000000  1.454134e+04  \n",
       "17         4.329569e+03  0.026932  1.607599e+05  \n",
       "18         0.000000e+00  0.000000  8.828549e+02  \n",
       "19         0.000000e+00  0.000000  2.921892e+05  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use 10% as threshold\n",
    "calculate_wilderness_marine(quantiles[-1], ['PROVINCE', 'PROVINCE_P', 'category']).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Further aggregation could be applied here, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Overlap between biogeography and marine pressure (new threshold for within EEZ)\n",
    "The World Heritage Convention currently operates only within areas under national jurisdiction, and thus high seas/ABNJ is not to be considered. It is sensible to reduce the scope of area of interest to the extent of EEZ, and accordingly adjust wilderness threshold values. \n",
    "\n",
    "By excluding Antartica, where significant area of wilderness exist, it should raise the bar lower for those to be considered as wilderness areas, i.e. having a higher cumulative marine pressure threshold and more areas would be 'eligible' as wilderness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data integrity\n",
    "input_data.OBJECTID.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160682670"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no zeros in the result data\n",
    "input_data.ras_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9654e-06"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it should not have 0, which indicates nodata in the raster data as it has been removed during the spatial analysis\n",
    "input_data.ras_val.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3875274645698689"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of EEZ water in relation to the entire ocean\n",
    "input_data.ras_val.size/g_array_f[~(g_array_f==0)].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all input_data are non-zero (zero indicates land and nodata)\n",
    "input_data[~(input_data.ras_val == 0)].ras_val.count() == input_data.ras_val.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get threshold for 10%\n",
    "new_threshold = np.percentile(input_data.ras_val, 10)\n",
    "old_threshold = np.percentile(g_array_f[~(g_array_f == 0)], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the new threshold (based on EEZ) and the function defined in the previous section to output lists of:\n",
    "- all meow provinces (including both 200 meter depth and 200 nautical miles (views) - wilderness area and percentage cover\n",
    "- both provinces, meow and pelagic, within EEZ - wilderness area and percentage cover\n",
    "\n",
    "It is possible for other combinations or different threshold if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'export_meow_province.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d3ad25a62820>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# export wilderness distribution by province or other groupings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcalculate_wilderness_marine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PROVINCE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'export_meow_province.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcalculate_wilderness_marine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'PROVINCE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PROVINCE_P'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'export_province_full.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yichuans\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1344\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yichuans\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1524\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1525\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1526\u001b[1;33m                             compression=self.compression)\n\u001b[0m\u001b[0;32m   1527\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yichuans\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'export_meow_province.csv'"
     ]
    }
   ],
   "source": [
    "# export wilderness distribution by province or other groupings\n",
    "calculate_wilderness_marine(new_threshold, ['PROVINCE']).to_csv('export_meow_province.csv')\n",
    "calculate_wilderness_marine(new_threshold, ['PROVINCE', 'PROVINCE_P', 'category']).to_csv('export_province_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distribution map of wilderness within EEZ using new threshold**\n",
    "![dist-eez](dist_EEZ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Distribution of percentage of wilderness (less than threshold, ltt) by groups**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# small multiples: distribution of percentage of less than threshold (ltt)\n",
    "g = sns.FacetGrid(calculate_wilderness_marine(new_threshold, ['PROVINCE', 'PROVINCE_P', 'category']), col=\"category\")\n",
    "g.map(plt.hist, 'per_ltt', bins=50, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MEOW province (200m and 200 nautical combined)\n",
    "sns.distplot(calculate_wilderness_marine(new_threshold, ['PROVINCE']).per_ltt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pelagic province\n",
    "sns.distplot(calculate_wilderness_marine(new_threshold, ['PROVINCE_P']).per_ltt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs, it is obvious that most provinces/pelagic provinces have very low percentage of marine wilderness area inside them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap between marine World Heritage sites and marine pressure\n",
    "The aim of this analysis is to understand wilderness marine area, as identified using methods in this study, inside the current WH sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wdpaid', 'ras_val'], dtype='object') Index(['objectid', 'wdpaid', 'en_name', 'fr_name', 'status_yr', 'rep_area',\n",
      "       'gis_area', 'country', 'crit', 'shape_Length', 'shape_Area'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "wh47 = pd.read_csv('wh47.csv')\n",
    "wh_attr = pd.read_csv('wh_attr.csv')\n",
    "\n",
    "print(wh47.columns, wh_attr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old threshold: 1.8049463033676147\n",
      "New threshold: 1.9568599999999998\n"
     ]
    }
   ],
   "source": [
    "# check thresholds, use new threshold\n",
    "print('Old threshold: {0}\\nNew threshold: {1}'.format(old_threshold, new_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'export_wh_wilderness.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-43f7055f26c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# export save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'export_wh_wilderness.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\yichuans\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1342\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1344\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yichuans\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1524\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1525\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1526\u001b[1;33m                             compression=self.compression)\n\u001b[0m\u001b[0;32m   1527\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yichuans\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'export_wh_wilderness.csv'"
     ]
    }
   ],
   "source": [
    "# get WH statics\n",
    "wh_n_base = (wh47.groupby('wdpaid').ras_val.count()*cell_size).reset_index()  # all marine area\n",
    "wh_n = (wh47[wh47.ras_val<new_threshold].groupby('wdpaid').ras_val.count()*cell_size).reset_index() # marine wild\n",
    "\n",
    "# merge in order to calculate percentage (% of marine wilderness in marine area of WH sites)\n",
    "a = pd.merge(wh_n_base, wh_n, on='wdpaid', suffixes=('_all', '_wild'))\n",
    "a = pd.merge(wh_attr, a, how='inner', on='wdpaid')\n",
    "a['per'] = a.ras_val_wild/a.ras_val_all\n",
    "\n",
    "# export save\n",
    "a.to_csv('export_wh_wilderness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distribution of WH wilderness percentage\n",
    "sns.distplot(a.per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(a.ras_val_wild)\n",
    "del a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gap analysis\n",
    "### 1. Mismatch of results using WH boundary alone vs WH intersections with biogeography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['OBJECTID', 'PROVINCE_P', 'BIOME_P', 'REALM_P', 'ECO_CODE', 'ECOREGION',\n",
       "        'PROV_CODE', 'PROVINCE', 'RLM_CODE', 'REALM', 'ALT_CODE', 'ECO_CODE_X',\n",
       "        'category', 'Shape_Length', 'Shape_Area'],\n",
       "       dtype='object'),\n",
       " Index(['objectid', 'wdpaid', 'en_name', 'fr_name', 'status_yr', 'rep_area',\n",
       "        'gis_area', 'country', 'crit', 'shape_Length', 'shape_Area'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_attr.columns, wh_attr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_wh = pd.read_csv('wh_base_intersect.csv')\n",
    "int_wh_attr = pd.read_csv('wh_base_intersect_attr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['OBJECTID_12', 'ras_val'], dtype='object'),\n",
       " Index(['OBJECTID_12', 'wdpaid', 'en_name', 'fr_name', 'status_yr', 'rep_area',\n",
       "        'gis_area', 'country', 'crit', 'unesid',\n",
       "        'FID_meow_meowv_pelagic_no_antarctica', 'PROVINCE_P', 'BIOME_P',\n",
       "        'REALM_P', 'ECO_CODE', 'ECOREGION', 'PROV_CODE', 'PROVINCE', 'RLM_CODE',\n",
       "        'REALM', 'ALT_CODE', 'ECO_CODE_X', 'category', 'Shape_Length',\n",
       "        'Shape_Area'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_wh.columns, int_wh_attr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_wh_attr[['wdpaid', 'en_name', 'gis_area', 'PROVINCE_P', 'PROVINCE', 'category']].to_csv('wh_biogeo_intersect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wdpaid     en_name                                                                    \n",
       "191        Galápagos Islands                                                               1951.711811\n",
       "2012       Everglades National Park                                                           1.746498\n",
       "2018       Kluane / Wrangell-St Elias / Glacier Bay / Tatshenshini-Alsek                   1352.662906\n",
       "2571       Great Barrier Reef                                                             78452.702062\n",
       "5004       Aldabra Atoll                                                                      5.239495\n",
       "9617       Gulf of Porto: Calanche of Piana, Gulf of Girolata, Scandola Reserve               0.873249\n",
       "20388      Banc d'Arguin National Park                                                      679.387825\n",
       "67724      Shark Bay, Western Australia                                                    1493.256017\n",
       "67726      Ujung Kulon National Park                                                          3.492997\n",
       "68918      Whale Sanctuary of El Vizcaino                                                   435.751317\n",
       "93767      Gough and Inaccessible Islands                                                    61.127439\n",
       "145576     Heard and McDonald Islands                                                      1956.951306\n",
       "145579     Macquarie Island                                                                5369.608916\n",
       "145582     Cocos Island National Park                                                       874.122382\n",
       "168239     New Zealand Sub-Antarctic Islands                                               6273.421768\n",
       "168242     East Rennell                                                                      41.915958\n",
       "198291     Península Valdés                                                                  19.211481\n",
       "198296     Area de Conservación Guanacaste                                                   84.705166\n",
       "198302     iSimangaliso Wetland Park                                                          6.985993\n",
       "478638     The Wadden Sea                                                                   301.270951\n",
       "478642     High Coast / Kvarken Archipelago                                                   3.492997\n",
       "900631     Brazilian Atlantic Islands: Fernando de Noronha and Atol das Rocas Reserves        0.873249\n",
       "900889     Ha Long Bay                                                                        8.732491\n",
       "902356     Natural System of Wrangel Island Reserve                                        5246.480788\n",
       "902368     St Kilda                                                                           0.873249\n",
       "902479     Coiba National Park and its Special Zone of Marine Protection                     38.422962\n",
       "902481     Islands and Protected Areas of the Gulf of California                           1768.329493\n",
       "902482     Shiretoko                                                                          1.746498\n",
       "902489     West Norwegian Fjords – Geirangerfjord and Nærøyfjord                              6.985993\n",
       "902899     Malpelo Fauna and Flora Sanctuary                                                144.086107\n",
       "903134     Lagoons of New Caledonia: Reef Diversity and Associated Ecosystems                93.437657\n",
       "903138     Socotra Archipelago                                                              169.410332\n",
       "555512001  Papahānaumokuākea                                                                956.207800\n",
       "555512002  Phoenix Islands Protected Area                                                 23492.148162\n",
       "555542338  Ningaloo Coast                                                                   186.875314\n",
       "555547992  Rock Islands Southern Lagoon                                                       2.619747\n",
       "Name: ras_val, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter pixels that meet the new threshold (from EEZ)\n",
    "int_wh_filter = int_wh[int_wh.ras_val < new_threshold]\n",
    "\n",
    "# group value based on OBJECTID\n",
    "int_wh_filter_group = int_wh_filter.groupby('OBJECTID_12').count().reset_index()\n",
    "\n",
    "# attr join\n",
    "int_result = pd.merge(int_wh_attr, int_wh_filter_group, on='OBJECTID_12')\n",
    "\n",
    "# % wilderness area inside each PA within EEZ\n",
    "int_result.groupby(['wdpaid', 'en_name']).ras_val.sum()*cell_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As contrary to common sense, wilderness in WH sites calculated from the intersection is slightly different from that of directly using WH boundary to cut out the marine cumulative impact data. This is due to boundary mismatches. The intersection of WH and EEZ (with biogeography attrs) removed all land area, where the marine pressure layer may have mapped pixels (See below highlighted pixels, in Galapogas)\n",
    "\n",
    "![boundary-mismatch](mis_boundary.PNG)\n",
    "\n",
    "Vice versa, due to the nature of intersection (clipping in strict sense), adjacent geometries having a long/shared boundary might pick up the same pixel from the base raster twice. **This should not be a problem due to very low occurence (upon manual checking) but it is possible to count the same pixel twice. This should not present a problem in most cases, although it could possibly be one if such a shared boundary is very long and complicated. **\n",
    "\n",
    "*In order to address this issue in the future, one could revert back to the old way: using an aggregated boundary for the result, however every change will mean a complete re-run. I would still prefer the fine granular approach, which far outweighs the shortcomings - do spatial once at the finest scale and the rest would be non-spatial. Subpixel level calculation is perhaps needed to determine whether or not an overlap should be counted or left out.*\n",
    "\n",
    "Futhermore, the mismatching issue is further plagued by spatial data quality. See below Natural System of Wrangel Island, where the blue part is the overlap between WH and biogeography\n",
    "\n",
    "![wrangel](wrangel_island.PNG)\n",
    "\n",
    "The only logical/sensible way to deal with this is to use WH calulation for its self (i.e. how much of wilderness is in WH system), while the intersection WH result for relations with biogeography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Below is an in-depth investigation but it's not part of the gap analysis**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate total WH marine area, no filter applied\n",
    "# group value based on OBJECTID\n",
    "int_wh_group = int_wh.groupby('OBJECTID_12').count().reset_index()\n",
    "\n",
    "# base \n",
    "G_base = (pd.merge(int_wh_attr, int_wh_group, on='OBJECTID_12').groupby(['wdpaid', 'en_name']).ras_val.sum()*cell_size).reset_index()\n",
    "G_wh = (int_result.groupby(['wdpaid', 'en_name']).ras_val.sum()*cell_size).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['wdpaid', 'en_name', 'ras_val'], dtype='object'),\n",
       " Index(['wdpaid', 'en_name', 'ras_val'], dtype='object'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_base.columns, G_wh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G_result = pd.merge(G_base, G_wh, how='left', on=('wdpaid', 'en_name'))\n",
    "G_result.fillna(0, inplace=True)\n",
    "G_result.columns = ['wdpaid', 'en_name', 'marine_area', 'marine_wild_area']\n",
    "G_result['per'] = G_result.marine_wild_area/G_result.marine_area\n",
    "# G_result.to_csv('export_wh_per_.csv')\n",
    "\n",
    "G_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wh47.columns, int_wh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wh47_int = pd.merge(int_wh, int_wh_attr, on='OBJECTID_12')\n",
    "wh47_int.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare differences from the two methods\n",
    "a = wh47.groupby('wdpaid').ras_val.count().reset_index()\n",
    "b = wh47_int.groupby('wdpaid').ras_val.count().reset_index()\n",
    "c = pd.merge(a, b, on='wdpaid', suffixes=('_wh', '_int'))\n",
    "c['per'] = abs(c.ras_val_wh - c.ras_val_int)/c.ras_val_wh\n",
    "# c\n",
    "\n",
    "del a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are considerable differences in percentage between the two methods to calculate marine areas within WH sites at first glance, however at the site scale, apart from wrangel Island, the differences are quite negliable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. the gap analysis\n",
    "The below is an overlay map between existing marine WH sites on top of wilderness identified.\n",
    "![dist-gap](dist_EEZ_WH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data to be used\n",
    "## wh intersection\n",
    "\n",
    "# filter pixels that meet the new threshold (from EEZ)\n",
    "int_wh_filter = int_wh[int_wh.ras_val < new_threshold]\n",
    "\n",
    "# group value based on OBJECTID\n",
    "int_wh_filter_group = int_wh_filter.groupby('OBJECTID_12').count().reset_index()\n",
    "\n",
    "# attr join\n",
    "int_result = pd.merge(int_wh_attr, int_wh_filter_group, on='OBJECTID_12')\n",
    "int_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get unique WDPAIDs for each province\n",
    "int_result.groupby('PROVINCE').wdpaid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get province MEOW (200m + 200nm)\n",
    "province = calculate_wilderness_marine(new_threshold, ['PROVINCE'])\n",
    "\n",
    "# provinces with WH sites, nunique() return unique number of WDPAIDs\n",
    "province_wh_number = pd.merge(province, int_result.groupby('PROVINCE').wdpaid.nunique().reset_index(), on='PROVINCE', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above does not say anything about wilderness, although by linking it with the provinces of wilderness values it could potentially identify prioirity provinces, however the above does not address the questions of how much of widerness is covered by WH sites. It could be a well 'represented' province may have little of its vast wilderness enjoying WH status, thus it may still presents a gap, from the point of view of marine wilderness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WH area that are wilderness area within provinces \n",
    "province_wh_wilderness = (int_result.groupby('PROVINCE').ras_val.sum() * cell_size).reset_index()\n",
    "\n",
    "# get province attributes and joi\n",
    "a = pd.merge(province, province_wh_wilderness, on='PROVINCE', how = 'left')\n",
    "\n",
    "# fill all NAs with 0\n",
    "a.fillna(0,inplace=True)\n",
    "\n",
    "# calculate percentage of province wilderness covered by WH\n",
    "a['per_wilderness_covered_by_WH'] = a.ras_val/a.less_than_threshold\n",
    "a.columns = ['PROVINCE', 'wilderness_area', 'per_wilderness_area', 'total_area', 'wh_wilderness_area', a.columns[-1]]\n",
    "\n",
    "\n",
    "# ======== now get number of WH sites per Province into one single dataframe ==========\n",
    "\n",
    "## num of WH sites\n",
    "b = int_result.groupby('PROVINCE').wdpaid.nunique().reset_index()\n",
    "b.columns = ['PROVINCE', 'num_wh']\n",
    "\n",
    "## merge \n",
    "a = pd.merge(a, b, how='left', on='PROVINCE')\n",
    "a.fillna(0, inplace=True)\n",
    "\n",
    "# a.sort_values('num_wh')\n",
    "a.to_csv('export_gap_meow_province.csv')\n",
    "\n",
    "# clear temp variable in case of polluting the global name space\n",
    "del a"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
